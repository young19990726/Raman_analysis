{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit, learning_curve, cross_val_score\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import log_loss, confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import Dimension_Reduce_Draw as DRD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './合併_6.csv'\n",
    "\n",
    "'''\n",
    "Target = 0 : 反應前\n",
    "Target = 1 : 加 acetone\n",
    "Target = 2 : 加 octanal\n",
    "Target = 3 : 加 heptanal\n",
    "'''\n",
    "\n",
    "'''validation 的 AUC = 0.96，test 的 AUC = 0.95，Average XGBscore: 0.81'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "################################################### 全部特徵 ###################################################\n",
    "data = pd.read_csv(file)\n",
    "data['Index'] = list(range(data.shape[0]))\n",
    "data.set_index('Index', inplace = True)\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, 1:n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "n_class = target.unique().size\n",
    "\n",
    "################################################### 抓特徵(相關係數) ###################################################\n",
    "corrs = []\n",
    "for c in feature.columns:\n",
    "    corr = np.corrcoef(feature[c], target)[0, 1]\n",
    "    corrs.append(corr)\n",
    "corrs = np.array(corrs)\n",
    "index = np.argsort(np.abs(corrs))[::-1]\n",
    "top_cols, top_importance = feature.columns.values[index][:300], corrs[index][:300]\n",
    "\n",
    "################################################### 新特徵並標準化 ###################################################\n",
    "feature = data.loc[:, top_cols]\n",
    "feature = StandardScaler().fit(feature).transform(feature) \n",
    "feature = pd.DataFrame(feature)\n",
    "\n",
    "################################################### optuna ###################################################\n",
    "def objective(trial):\n",
    "    params = {'objective': 'multi:softmax',\n",
    "              'eval_metric': 'mlogloss',\n",
    "              'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "              'max_depth': trial.suggest_int('max_depth', 6, 18),\n",
    "              'eta': trial.suggest_loguniform('eta', 1e-4, 1.0),\n",
    "              'random_state': trial.suggest_int('random_state', 1999, 2023),\n",
    "              'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "              'gamma': trial.suggest_loguniform('gamma', 1e-5, 10),\n",
    "              'subsample': trial.suggest_float('subsample', 0.001, 1.0),\n",
    "              'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 1e-3, 1),\n",
    "              'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "              'use_label_encoder': False,\n",
    "              'num_class': 4,\n",
    "              'seed': 42\n",
    "              }  \n",
    "    scores = []\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    for train_index, valid_index in kf.split(feature):\n",
    "        X_train, X_valid = feature.iloc[train_index], feature.iloc[valid_index]\n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], early_stopping_rounds = 10, verbose = False)\n",
    "        y_pred = model.predict_proba(X_valid)\n",
    "        score = log_loss(y_valid, y_pred)\n",
    "        scores.append(score)\n",
    "    mean_score = np.mean(scores)\n",
    "    return mean_score\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0), direction = 'minimize', study_name = 'lr', pruner = optuna.pruners.HyperbandPruner())\n",
    "study.optimize(objective, n_trials = 50)\n",
    "the_best_params = study.best_params\n",
    "\n",
    "################################################### 分訓練組、驗證組及測試組 ###################################################\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(feature, target, test_size = 0.4, random_state = 0, stratify = target)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_valid, y_valid, test_size = 0.5, random_state = 0, stratify = y_valid)     \n",
    "\n",
    "################################################### 建模並預測 ###################################################\n",
    "model_XGB = XGBClassifier(**the_best_params)\n",
    "model_XGB.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], early_stopping_rounds = 10, verbose = False)\n",
    "y_pred_valid = model_XGB.predict_proba(X_valid)\n",
    "y_pred_valid = [np.argmax(line) for line in y_pred_valid]\n",
    "y_pred_test = model_XGB.predict_proba(X_test) \n",
    "y_pred_test = [np.argmax(line) for line in y_pred_test]\n",
    "\n",
    "################################################### 學習曲線 ###################################################\n",
    "cv = ShuffleSplit(n_splits = 100, test_size = 0.2, random_state = 0) # 定義學習曲線的訓練集大小\n",
    "train_sizes, train_scores, test_scores = learning_curve(model_XGB, X_train, y_train, cv = cv, n_jobs = -1, train_sizes = np.linspace(.1, 1.0, 5), scoring = \"accuracy\") # 繪製學習曲線 \n",
    "train_mean = np.mean(train_scores, axis = 1) # 計算平均分數和標準差\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Learning Curve')\n",
    "plt.plot(train_sizes, train_mean, 'o-', color = \"r\", label = \"Training score\")\n",
    "plt.plot(train_sizes, test_mean, 'o-', color = \"g\", label = \"Cross-validation score\")\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha = 0.1, color = \"r\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha = 0.1, color = \"g\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "################################################### Validation 混淆矩陣 ###################################################\n",
    "labels = np.unique(y_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred_valid, labels = labels)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (5, 4))\n",
    "sns.heatmap(cm_df, annot = True, cmap = 'summer')\n",
    "plt.title('Confusion Matrix Validation')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.show()\n",
    "\n",
    "################################################### Test 混淆矩陣 ###################################################\n",
    "labels = np.unique(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels = labels)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (5, 4))\n",
    "sns.heatmap(cm_df, annot = True, cmap = 'summer')\n",
    "plt.title('Confusion Matrix Test')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.show()\n",
    "\n",
    "################################################### 評價模型 ###################################################\n",
    "print('訓練集: ', model_XGB.score(X_train, y_train))\n",
    "print('驗證集: ', model_XGB.score(X_valid, y_valid))\n",
    "print(classification_report(y_valid, y_pred_valid))\n",
    "print('測試集: ', model_XGB.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "################################################### Validation AUC ###################################################\n",
    "y_valid = label_binarize(y_valid, np.arange(n_class))\n",
    "y_pred_valid = model_XGB.predict_proba(X_valid)\n",
    "fpr, tpr, threshold = roc_curve(y_valid.ravel(), y_pred_valid.ravel())\n",
    "auc_1 = auc(fpr, tpr)\n",
    "plt.title('Validation AUC')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc_1)\n",
    "plt.plot([0, 1], [0, 1], c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.legend(loc = 'lower right', fancybox = True, framealpha = 0.8, fontsize = 12)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize = 13)\n",
    "plt.ylabel('True Positive Rate', fontsize = 13)\n",
    "plt.grid(b = True, ls = ':')\n",
    "plt.show()\n",
    "\n",
    "################################################### Test AUC ###################################################\n",
    "y_test = label_binarize(y_test, np.arange(n_class))\n",
    "y_pred_test = model_XGB.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test.ravel(), y_pred_test.ravel())\n",
    "auc_1 = auc(fpr, tpr)\n",
    "plt.title('Test AUC')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc_1)\n",
    "plt.plot([0, 1], [0, 1], c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.legend(loc = 'lower right', fancybox = True, framealpha = 0.8, fontsize = 12)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize = 13)\n",
    "plt.ylabel('True Positive Rate', fontsize = 13)\n",
    "plt.grid(b = True, ls = ':')\n",
    "plt.show()\n",
    "\n",
    "################################################### 特徵重要性 ###################################################\n",
    "plot_importance(model_XGB, max_num_features = 30)\n",
    "plt.show()\n",
    "\n",
    "################################################### 交叉驗證後的正確率 ###################################################\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "XGBscore = cross_val_score(XGBClassifier(**the_best_params), feature, target, cv = kf, scoring = \"accuracy\")\n",
    "print(f'XGBscore for each fold are: {XGBscore}')\n",
    "print(f'Average XGBscore: {\"{:.2f}\".format(XGBscore.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Importance](https://machinelearningmastery.com/calculate-feature-importance-with-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DRD.Draw_PCA_Multi(file)\n",
    "DRD.Draw_t_SNE_Multi(file)\n",
    "DRD.Draw_UMAP_Multi(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "################################################### 全部特徵 ###################################################\n",
    "data = pd.read_csv(file)\n",
    "data['Index'] = list(range(data.shape[0]))\n",
    "data.set_index('Index', inplace = True)\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, 1:n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "\n",
    "################################################### 抓特徵(相關係數) ###################################################\n",
    "corrs = []\n",
    "for c in feature.columns:\n",
    "    corr = np.corrcoef(feature[c], target)[0, 1]\n",
    "    corrs.append(corr)\n",
    "corrs = np.array(corrs)\n",
    "index = np.argsort(np.abs(corrs))[::-1]\n",
    "top_cols, top_importance = feature.columns.values[index][:300], corrs[index][:300]\n",
    "\n",
    "################################################### 新特徵並標準化 ###################################################\n",
    "feature = data.loc[:, top_cols]\n",
    "feature = StandardScaler().fit(feature).transform(feature) \n",
    "feature = pd.DataFrame(feature)\n",
    "data = pd.merge(feature, target, left_index = True, right_index = True)\n",
    "\n",
    "################################################### PCA ###################################################\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, :n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "pca = PCA(n_components = 3).fit(feature).transform(feature)\n",
    "Xax = pca[:, 0]\n",
    "Yax = pca[:, 1]\n",
    "Zax = pca[:, 2]\n",
    "color = {0:'red', 1:'skyblue', 2:'green', 3:'purple'}\n",
    "label = {0:'before', 1:'acetone', 2:'octanal', 3:'heptanal'}\n",
    "marker = {0:'*', 1:'*', 2:'*', 3:'*'}\n",
    "alpha = {0:.3, 1:.5, 2:.3, 3:.5}\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_zlabel('Principal Component 3', fontsize = 15)\n",
    "ax.set_title('acetone_51', fontsize = 15)\n",
    "fig.patch.set_facecolor('white')\n",
    "for i in np.unique(target):\n",
    "    ix = np.where(target == i)\n",
    "    ax.scatter(Xax[ix], Yax[ix], Zax[ix], c = color[i], s = 40, label = label[i], marker = marker[i], alpha = alpha[i])\n",
    "ax.grid()\n",
    "plt.show()\n",
    "df = pd.DataFrame(pca, columns = ('x', 'y', 'z'))\n",
    "df[\"class\"] = target\n",
    "df[\"class\"] = df[\"class\"].replace({0:'before', 1:'acetone', 2:'octanal', 3:'heptanal'})\n",
    "pca_interactive = px.scatter_3d(df, x = 'x', y = 'y', z = 'z', color = 'class', title = 'acetone_51')\n",
    "pca_interactive.update_traces(marker_size = 5)\n",
    "pca_interactive.show()  \n",
    "\n",
    "################################################### t_SNE ###################################################\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, :n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "t_SNE = TSNE(n_components = 2, init = 'random', random_state = 5, verbose = 1).fit_transform(feature)\n",
    "x_min, x_max = t_SNE.min(0), t_SNE.max(0)\n",
    "X_norm = (t_SNE - x_min) / (x_max - x_min)\n",
    "plt.figure(figsize = (5, 5))\n",
    "for i in range(X_norm.shape[0]):\n",
    "    plt.text(X_norm[i, 0], X_norm[i, 1], str(target[i]), color = plt.cm.Set1(target[i]), fontdict = {'weight': 'bold', 'size': 9})\n",
    "plt.title('acetone_51', fontsize = 15)   \n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "t_SNE = TSNE(n_components = 3, init = 'random', random_state = 5, verbose = 1).fit_transform(feature)\n",
    "df = pd.DataFrame(t_SNE, columns = ('x', 'y', 'z'))\n",
    "df[\"class\"] = target\n",
    "df[\"class\"] = df[\"class\"].replace({0:'before', 1:'acetone', 2:'octanal', 3:'heptanal'})\n",
    "t_SNE_interactive = px.scatter_3d(df, x = 'x', y = 'y', z = 'z', color = 'class', title = 'acetone_51')\n",
    "t_SNE_interactive.update_traces(marker_size = 5)\n",
    "t_SNE_interactive.show()\n",
    "\n",
    "################################################### UMAP ###################################################\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, :n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "embedding = UMAP(random_state = 42).fit_transform(feature)\n",
    "df = pd.DataFrame(embedding, columns = ('x', 'y'))\n",
    "df[\"class\"] = target\n",
    "df[\"class\"] = df[\"class\"].replace({0:'before', 1:'acetone', 2:'octanal', 3:'heptanal'})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "ax = sns.pairplot(x_vars = [\"x\"], y_vars = [\"y\"], data = df, hue = \"class\", size = 5, plot_kws = {\"s\": 20})\n",
    "ax.fig.suptitle('acetone_51', fontsize = 15)\n",
    "plt.show()\n",
    "proj_3d = UMAP(n_components = 3, init = 'random', random_state = 0).fit_transform(feature)\n",
    "df = pd.DataFrame(proj_3d, columns = ('x', 'y', 'z'))\n",
    "df[\"class\"] = target\n",
    "df[\"class\"] = df[\"class\"].replace({0:'before', 1:'acetone', 2:'octanal', 3:'heptanal'})\n",
    "UMAP_interactive = px.scatter_3d(df, x = 'x', y = 'y', z = 'z', color = 'class', title = 'acetone_51')\n",
    "UMAP_interactive.update_traces(marker_size = 5)\n",
    "UMAP_interactive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './all_6.csv'\n",
    "test_file = './all_6_new.csv'\n",
    "\n",
    "'''\n",
    "all_6 預測 validation 的 AUC = 0.98\n",
    "all_6 預測 all_6_new(test) 的 AUC = 0.80\n",
    "\n",
    "Average XGBscore: 0.86\n",
    "'''\n",
    "\n",
    "'''\n",
    "all_6_new 預測 validation 的 AUC = 0.92\n",
    "all_6_new 預測 all_6(test) 的 AUC = 0.80\n",
    "\n",
    "Average XGBscore: 0.86\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "################################################### 全部特徵 ###################################################\n",
    "data = pd.read_csv(train_file)\n",
    "data['Index'] = list(range(data.shape[0]))\n",
    "data.set_index('Index', inplace = True)\n",
    "n_columns = data.shape[1] - 1\n",
    "feature = data.iloc[:, 1:n_columns]\n",
    "target = data.iloc[:, n_columns]\n",
    "n_class = target.unique().size\n",
    "\n",
    "################################################### 抓特徵(相關係數) ###################################################\n",
    "corrs = []\n",
    "for c in feature.columns:\n",
    "    corr = np.corrcoef(feature[c], target)[0, 1]\n",
    "    corrs.append(corr)\n",
    "corrs = np.array(corrs)\n",
    "index = np.argsort(np.abs(corrs))[::-1]\n",
    "top_cols, top_importance = feature.columns.values[index][:100], corrs[index][:100]\n",
    "\n",
    "################################################### 新特徵並標準化 ###################################################\n",
    "feature = data.loc[:, top_cols]\n",
    "feature = StandardScaler().fit(feature).transform(feature) \n",
    "feature = pd.DataFrame(feature)\n",
    "\n",
    "################################################### optuna ###################################################\n",
    "def objective(trial):\n",
    "    params = {'objective': 'multi:softmax',\n",
    "              'eval_metric': 'mlogloss',\n",
    "              'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "              'max_depth': trial.suggest_int('max_depth', 6, 18),\n",
    "              'eta': trial.suggest_loguniform('eta', 1e-3, 1.0),\n",
    "              'random_state': trial.suggest_int('random_state', 1999, 2023),\n",
    "              'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "              'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "              'subsample': trial.suggest_loguniform('subsample', 0.1, 1.0),\n",
    "              'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "              'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "              'use_label_encoder': False,\n",
    "              'num_class': 4,\n",
    "              'seed': 42\n",
    "              }  \n",
    "    scores = []\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    for train_index, valid_index in kf.split(feature):\n",
    "        X_train, X_valid = feature.iloc[train_index], feature.iloc[valid_index]\n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], early_stopping_rounds = 10, verbose = False)\n",
    "        y_pred = model.predict_proba(X_valid)\n",
    "        score = log_loss(y_valid, y_pred)\n",
    "        scores.append(score)\n",
    "    mean_score = np.mean(scores)\n",
    "    return mean_score\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0), direction = 'minimize', study_name = 'lr', pruner = optuna.pruners.HyperbandPruner())\n",
    "study.optimize(objective, n_trials = 50)\n",
    "the_best_params = study.best_params\n",
    "\n",
    "################################################### 分訓練組、驗證組及測試組 ###################################################\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(feature, target, test_size = 0.4, random_state = 0, stratify = target)\n",
    "test = pd.read_csv(test_file)\n",
    "test['Index'] = list(range(test.shape[0]))\n",
    "test.set_index('Index', inplace = True)\n",
    "n_columns = test.shape[1] - 1\n",
    "X_test = test.loc[:, top_cols]\n",
    "y_test = test.iloc[:, n_columns]\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test) \n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, test_size = 0.6, random_state = 0, stratify = y_test)\n",
    "\n",
    "################################################### 建模並預測 ###################################################\n",
    "model_XGB = XGBClassifier(**the_best_params)\n",
    "model_XGB.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], early_stopping_rounds = 10, verbose = False)\n",
    "y_pred_valid = model_XGB.predict_proba(X_valid)\n",
    "y_pred_valid = [np.argmax(line) for line in y_pred_valid]\n",
    "y_pred_test = model_XGB.predict_proba(X_test) \n",
    "y_pred_test = [np.argmax(line) for line in y_pred_test]\n",
    "\n",
    "################################################### 學習曲線 ###################################################\n",
    "cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0) # 定義學習曲線的訓練集大小\n",
    "train_sizes, train_scores, test_scores = learning_curve(model_XGB, X_train, y_train, cv = cv, n_jobs = -1, train_sizes = np.linspace(.1, 1.0, 5), scoring = \"accuracy\") # 繪製學習曲線 \n",
    "train_mean = np.mean(train_scores, axis = 1) # 計算平均分數和標準差\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "plt.title('Learning Curve')\n",
    "plt.plot(train_sizes, train_mean, 'o-', color = \"r\", label = \"Training score\")\n",
    "plt.plot(train_sizes, test_mean, 'o-', color = \"g\", label = \"Cross-validation score\")\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha = 0.1, color = \"r\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha = 0.1, color = \"g\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "################################################### Validation 混淆矩陣 ###################################################\n",
    "labels = np.unique(y_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred_valid, labels = labels)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (5, 4))\n",
    "sns.heatmap(cm_df, annot = True, cmap = 'summer')\n",
    "plt.title('Confusion Matrix Validation')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.show()\n",
    "\n",
    "################################################### Test 混淆矩陣 ###################################################\n",
    "labels = np.unique(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels = labels)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (5, 4))\n",
    "sns.heatmap(cm_df, annot = True, cmap = 'summer')\n",
    "plt.title('Confusion Matrix Test')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.show()\n",
    "\n",
    "################################################### 評價模型 ###################################################\n",
    "print('訓練集: ', model_XGB.score(X_train, y_train))\n",
    "print('驗證集: ', model_XGB.score(X_valid, y_valid))\n",
    "print(classification_report(y_valid, y_pred_valid))\n",
    "print('測試集: ', model_XGB.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "################################################### Validation AUC ###################################################\n",
    "y_valid = label_binarize(y_valid, np.arange(n_class))\n",
    "y_pred_valid = model_XGB.predict_proba(X_valid)\n",
    "fpr, tpr, threshold = roc_curve(y_valid.ravel(), y_pred_valid.ravel())\n",
    "auc_1 = auc(fpr, tpr)\n",
    "plt.title('Validation AUC')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc_1)\n",
    "plt.plot([0, 1], [0, 1], c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.legend(loc = 'lower right', fancybox = True, framealpha = 0.8, fontsize = 12)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize = 13)\n",
    "plt.ylabel('True Positive Rate', fontsize = 13)\n",
    "plt.grid(b = True, ls = ':')\n",
    "plt.show()\n",
    "\n",
    "################################################### Test AUC ###################################################\n",
    "y_test = label_binarize(y_test, np.arange(n_class))\n",
    "y_pred_test = model_XGB.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test.ravel(), y_pred_test.ravel())\n",
    "auc_1 = auc(fpr, tpr)\n",
    "plt.title('Test AUC')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc_1)\n",
    "plt.plot([0, 1], [0, 1], c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.legend(loc = 'lower right', fancybox = True, framealpha = 0.8, fontsize = 12)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize = 13)\n",
    "plt.ylabel('True Positive Rate', fontsize = 13)\n",
    "plt.grid(b = True, ls = ':')\n",
    "plt.show()\n",
    "\n",
    "################################################### 特徵重要性 ###################################################\n",
    "plot_importance(model_XGB, max_num_features = 30)\n",
    "plt.show()\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "XGBscore = cross_val_score(XGBClassifier(**the_best_params), feature, target, cv = kf, scoring = \"accuracy\")\n",
    "print(f'XGBscore for each fold are: {XGBscore}')\n",
    "print(f'Average XGBscore: {\"{:.2f}\".format(XGBscore.mean())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
